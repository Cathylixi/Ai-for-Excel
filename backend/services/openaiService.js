const OpenAI = require('openai');
const cheerio = require('cheerio');

// åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

/**
 * Identify the Assessment Schedule from PDF tables (array-based) using AI.
 * This mirrors the Word HTML flow but adapts the prompt to 2D array tables.
 *
 * @param {Array} tables - Array of PDF tables with shape: { data: string[][], rows: number, columns: number, page?: number, table_index?: number }
 * @returns {Promise<null|{ tableIndex: number, data: string[][], page?: number, rows: number, columns: number, confidence: number, identifiedBy: string, reason?: string }>}
 */
async function identifyAssessmentScheduleForPdfTables(tables) {
  try {
    if (!Array.isArray(tables) || tables.length === 0) {
      return null;
    }

    // console.log('ğŸ¤– Start AI identification for PDF Assessment Schedule...');

    for (let i = 0; i < tables.length; i++) {
      const table = tables[i] || {};
      const data = Array.isArray(table.data) ? table.data : [];
      const headers = Array.isArray(data[0]) ? data[0] : [];
      const firstRow = Array.isArray(data[1]) ? data[1] : [];
      const totalRows = Number(table.rows || data.length || 0);
      const totalCols = Number(table.columns || (Array.isArray(headers) ? headers.length : 0));

      const timepointHit = headers.filter(h => h && /(visit|day|week|month|cycle|screening|baseline|follow)/i.test(String(h))).length > 0 ? 'YES' : 'NO';

      const prompt = `You are a clinical trial data expert. Your task is to identify the MAIN "Schedule of Assessment" or "Schedule of Events" table that contains the comprehensive visit-by-procedure matrix for the entire study.

WHAT WE'RE LOOKING FOR:
This must be the PRIMARY schedule table that shows:
- COMPREHENSIVE list of study procedures/assessments (typically 10+ different types)
- MULTIPLE study visits/timepoints (typically 5+ visits like Screening, Baseline, Week 2, Week 4, Month 3, etc.)
- MATRIX format showing which procedures happen at which visits (usually marked with X, â€¢, or checkmarks)

MUST CONTAIN DIVERSE ASSESSMENT TYPES:
- Laboratory tests (blood work, chemistry, hematology)
- Vital signs (blood pressure, heart rate, temperature)
- Physical examinations
- Medical history/concomitant medications
- Questionnaires/quality of life assessments
- Safety assessments/adverse events
- Study drug administration/accountability

REJECT if table contains:
- Only a few specific procedures (< 8 procedures)
- Only one type of assessment (e.g., only imaging, only questionnaires)
- Limited timepoints (< 4 visits)
- Detailed sub-procedures of one main assessment
- Summary or subset tables

Table Analysis (array-based table):
- Headers: ${headers.join(', ')}
- First data row: ${firstRow.join(', ')}
- Total rows: ${totalRows}, Total columns: ${totalCols}

Key indicators:
- Contains timepoint keywords? ${timepointHit}
- Multiple columns (3+)? ${totalCols >= 3 ? 'YES' : 'NO'}
- Multiple rows (8+)? ${totalRows >= 8 ? 'YES' : 'NO'}

Is this the MAIN comprehensive Schedule of Assessment for the study? Respond ONLY with JSON:
{
  "isAssessmentSchedule": true/false,
  "confidence": 0.0-1.0,
  "reason": "Brief explanation focusing on comprehensiveness and diversity"
}`;

      try {
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [{ role: 'user', content: prompt }],
          max_tokens: 200,
          temperature: 0.1
        });

        const aiText = (response.choices?.[0]?.message?.content || '').trim();
        // console.log(`ğŸ“Š PDF table ${i} AI reply:`, aiText);

        let analysis;
        try {
          analysis = JSON.parse(aiText);
        } catch (e) {
          const start = aiText.indexOf('{');
          const end = aiText.lastIndexOf('}') + 1;
          if (start >= 0 && end > start) {
            analysis = JSON.parse(aiText.slice(start, end));
          } else {
            throw e;
          }
        }

        if (analysis && analysis.isAssessmentSchedule && Number(analysis.confidence) > 0.7) {
          console.log(`âœ… Found PDF Assessment Schedule at index ${i}, confidence ${analysis.confidence}`);
          return {
            tableIndex: typeof table.table_index === 'number' ? table.table_index : i,
            data: data,
            page: table.page,
            rows: totalRows,
            columns: totalCols,
            confidence: Number(analysis.confidence) || 0.7,
            identifiedBy: 'ai_pdf',
            reason: analysis.reason || undefined
          };
        }
      } catch (apiError) {
        console.warn(`âš ï¸ AI identification failed for PDF table ${i}: ${apiError.message}`);
      }

      // Small delay to avoid bursting the API
      await new Promise(r => setTimeout(r, 200));
    }

    // console.log('âŒ No Assessment Schedule identified among PDF tables');
    return null;
  } catch (err) {
    console.error('âŒ identifyAssessmentScheduleForPdfTables failed:', err.message);
    return null;
  }
}

// AIè¯†åˆ«è¯„ä¼°æ—¶é—´è¡¨å‡½æ•°
async function identifyAssessmentScheduleWithAI(tables) {
  try {
    // console.log('ğŸ¤– å¼€å§‹ä½¿ç”¨AIè¯†åˆ«è¯„ä¼°æ—¶é—´è¡¨...');
    
    for (let i = 0; i < tables.length; i++) {
      const table = tables[i];
      
      // ä¸ºäº†èŠ‚çœAPIè°ƒç”¨æˆæœ¬ï¼Œæˆ‘ä»¬åªåˆ†æè¡¨æ ¼çš„å‰å‡ è¡Œæ¥åˆ¤æ–­
      const $ = cheerio.load(table.htmlContent);
      
      // æå–è¡¨æ ¼çš„ç»“æ„ä¿¡æ¯ç”¨äºAIåˆ¤æ–­
      const tableStructure = {
        headers: [],
        firstRowData: [],
        totalRows: $('tr').length,
        totalCols: $('th, td').length
      };
      
      // æå–è¡¨å¤´
      $('thead tr:first th, tr:first th, tr:first td').each(function() {
        tableStructure.headers.push($(this).text().trim());
      });
      
      // æå–ç¬¬ä¸€è¡Œæ•°æ®
      $('tbody tr:first td, tr:eq(1) td').each(function() {
        tableStructure.firstRowData.push($(this).text().trim());
      });
      
      // æ„å»ºç»™AIçš„prompt - é‡æ–°è®¾è®¡ä¸ºåŠŸèƒ½æ€§è¯†åˆ«
      const prompt = `You are a clinical trial data expert. Your task is to identify tables suitable for SDTM conversion - specifically tables that map study visits/timepoints to assessments/procedures.

**FUNCTIONAL PURPOSE:**
We need tables that can be used to generate SDTM domains by mapping:
- VISIT numbers/timepoints to assessment procedures
- WHEN (visit/day/week/month) specific assessments occur
- A structured schedule for data collection activities

**ACCEPT tables that contain:**
1. **Multiple timepoints** - Visit 1, Visit 2, Day 1, Wk2, Month 4, Baseline, Follow-up, Screening, etc.
2. **Assessment activities** - Labs, vitals, questionnaires, procedures, evaluations, etc.
3. **Visit-procedure mapping** - Shows WHICH assessments happen at WHICH visits
4. **Matrix/schedule format** - Structured layout showing time vs. activities relationship

**Table titles might include:**
- "Schedule of Events", "Schedule of Assessments", "Visit Schedule"  
- "Study Timeline", "Assessment Calendar", "Procedure Schedule"
- Or even generic titles if content shows visit-assessment mapping

**REJECT tables that are:**
- Synopsis/summary (narrative descriptions)
- Demographics/baseline characteristics
- Table of Contents, abbreviations, references
- Pure administrative text without visit structure

**Table Analysis:**
- **Headers:** ${tableStructure.headers.join(', ')}
- **First data row:** ${tableStructure.firstRowData.join(', ')}
- **Total rows:** ${tableStructure.totalRows}, **Total columns:** ${tableStructure.totalCols}

**Key indicators:**
- Contains timepoint keywords? ${tableStructure.headers.filter(h => h.match(/(visit|day|week|month|cycle|screening|baseline|follow)/i)).length > 0 ? 'YES' : 'NO'}
- Multiple columns (3+)? ${tableStructure.totalCols >= 3 ? 'YES' : 'NO'}
- Multiple rows (3+)? ${tableStructure.totalRows >= 3 ? 'YES' : 'NO'}

Can this table be used to create an SDTM visit schedule? Respond ONLY with JSON:
{
  "isAssessmentSchedule": true/false,
  "confidence": 0.0-1.0,
  "reason": "Brief functional explanation"
}`;

      try {
        const response = await openai.chat.completions.create({
          model: "gpt-3.5-turbo",
          messages: [
            {
              role: "user",
              content: prompt
            }
          ],
          max_tokens: 200,
          temperature: 0.1
        });
        
        const aiResponse = response.choices[0].message.content.trim();
        // console.log(`ğŸ“Š è¡¨æ ¼ ${i} AIå›å¤:`, aiResponse);
        
        // è§£æAIçš„JSONå›å¤
        const analysis = JSON.parse(aiResponse);
        
        if (analysis.isAssessmentSchedule && analysis.confidence > 0.7) {
          // console.log(`âœ… æ‰¾åˆ°è¯„ä¼°æ—¶é—´è¡¨! è¡¨æ ¼ç´¢å¼•: ${i}, ç½®ä¿¡åº¦: ${analysis.confidence}`);
          return {
            tableIndex: i,
            htmlContent: table.htmlContent,
            confidence: analysis.confidence,
            identifiedBy: 'ai',
            reason: analysis.reason
          };
        }
        
      } catch (apiError) {
        console.warn(`âš ï¸ AI APIè°ƒç”¨å¤±è´¥ (è¡¨æ ¼ ${i}):`, apiError.message);
        continue; // ç»§ç»­æ£€æŸ¥ä¸‹ä¸€ä¸ªè¡¨æ ¼
      }
      
      // æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
      await new Promise(resolve => setTimeout(resolve, 500));
    }
    
    // console.log('âŒ æœªæ‰¾åˆ°è¯„ä¼°æ—¶é—´è¡¨');
    
    // å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºå…³é”®è¯ç›´æ¥è¯†åˆ«Schedule of Events
    // console.log('ğŸ” å¯ç”¨å¤‡ç”¨è¯†åˆ«ï¼šåŸºäºå…³é”®è¯åŒ¹é…...');
    for (let i = 0; i < tables.length; i++) {
      const table = tables[i];
      const title = (table.title || '').toLowerCase();
      
      if (title.includes('schedule of events') || 
          title.includes('schedule of assessments') ||
          (title.includes('schedule') && title.includes('section'))) {
        // console.log(`âœ… å¤‡ç”¨æ–¹æ¡ˆè¯†åˆ«æˆåŠŸ: "${table.title}"`);
        return {
          tableIndex: i,
          htmlContent: table.htmlContent,
          confidence: 0.8,
          identifiedBy: 'keyword-backup',
          reason: 'Identified by keyword matching (backup method)',
          functionalType: 'schedule-of-events-keyword-match'
        };
      }
    }
    
    return null;
    
  } catch (error) {
    console.error('âŒ AIè¯†åˆ«è¯„ä¼°æ—¶é—´è¡¨å¤±è´¥:', error);
    return null;
  }
}

// â¬‡ï¸ æ–°å¢ï¼šAI æå– Study Numberï¼ˆå¸¦æ­£åˆ™å…œåº•ï¼‰
async function extractStudyNumber(fullText) {
  try {
    if (!fullText || typeof fullText !== 'string') return null;

    // å–å‰é¢çš„æ–‡æœ¬ï¼Œä½†è¦åŒ…å«è¶³å¤Ÿçš„é¡µé¢æ¥è¯†åˆ«é‡å¤patternï¼ˆå¢åŠ åˆ°8000å­—ç¬¦ï¼‰
    const head = fullText.slice(0, 8000);

    const prompt = `Extract study number and page header from this clinical protocol text:

1. STUDY NUMBER: Find protocol/study identifier (like "SPI-611", "ABC-123")

2. PAGE HEADER: Find text that repeats on every page
   - May be single line or multiple lines
   - Replace actual page numbers with PAGE_NUM
   - Include exactly what repeats, nothing more or less

Return ONLY valid JSON with curly braces:

Examples:
{"studyNumber": "XYZ-123", "headerPattern": "Study XYZ-123 Draft 2 Page PAGE_NUM of 30", "hasHeader": true}
{"studyNumber": "DEF-456", "headerPattern": "Protocol DEF-456 Version 1.0 Page PAGE_NUM of 25\nConfidential Document", "hasHeader": true}  
{"studyNumber": "GHI-789", "headerPattern": null, "hasHeader": false}

TEXT:
${head}`;

    // console.log('ğŸ¤– ===== AI HEADER DETECTION START =====');
    // console.log(`ğŸ¤– Input text length: ${head.length} characters`);
    // console.log('ğŸ¤– Calling OpenAI GPT-4 for Study Number and Header detection...');
    
    const resp = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.1,
      max_tokens: 200  // Increased for better header detection
    });

    const content = (resp.choices?.[0]?.message?.content || '').trim();
    // console.log(`ğŸ¤– AI raw response: ${content}`);
    // console.log('ğŸ¤– Parsing AI response...');
    
    let result = { studyNumber: null, headerInfo: null };
    
    try {
      const json = JSON.parse(content);
      
      // console.log('ğŸ¤– ===== AI JSON RESPONSE BREAKDOWN =====');
      // console.log(`ğŸ¤– studyNumber: "${json.studyNumber || 'null'}"`);
      // console.log(`ğŸ¤– hasHeader: ${json.hasHeader || 'false'}`);
      // console.log(`ğŸ¤– headerPattern: "${json.headerPattern || 'null'}"`);
      // console.log('ğŸ¤– ========================================');
      
      // Extract study number
      result.studyNumber = (json && json.studyNumber && json.studyNumber !== 'N/A') 
        ? String(json.studyNumber).trim() : null;
      // console.log(`ğŸ¤– Extracted Study Number: "${result.studyNumber}"`);
      
      // Extract header info
      if (json && json.hasHeader && json.headerPattern) {
        result.headerInfo = {
          hasHeader: json.hasHeader,
          headerPattern: json.headerPattern
        };
        // console.log(`ğŸ¤– âœ… HEADER DETECTED!`);
        // console.log(`ğŸ¤– Header Pattern: "${json.headerPattern}"`);
        // console.log(`ğŸ¤– Has Header: ${json.hasHeader}`);
      } else {
        // console.log(`ğŸ¤– âŒ NO HEADER DETECTED`);
        // console.log(`ğŸ¤– Reason: hasHeader=${json ? json.hasHeader : 'unknown'}, pattern=${json ? json.headerPattern : 'unknown'}`);
        result.headerInfo = null;
      }
      
    } catch (e) {
      // console.log(`ğŸ¤– âš ï¸ JSON parsing failed: ${e.message}`);
      // console.log('ğŸ¤– Attempting fallback parsing...');
      
      // å¦‚æœä¸æ˜¯çº¯JSONï¼Œå°è¯•æå–èŠ±æ‹¬å·å†…JSON
      const start = content.indexOf('{');
      const end = content.lastIndexOf('}');
      if (start >= 0 && end > start) {
        const extractedJson = content.slice(start, end + 1);
        // console.log(`ğŸ¤– Extracted JSON from response: ${extractedJson}`);
        
        try {
          const json = JSON.parse(extractedJson);
          
          // console.log('ğŸ¤– ===== FALLBACK JSON RESPONSE BREAKDOWN =====');
          // console.log(`ğŸ¤– studyNumber: "${json.studyNumber || 'null'}"`);
          // console.log(`ğŸ¤– hasHeader: ${json.hasHeader || 'false'}`);
          // console.log(`ğŸ¤– headerPattern: "${json.headerPattern || 'null'}"`);
          // console.log('ğŸ¤– ============================================');
          
          result.studyNumber = (json && json.studyNumber && json.studyNumber !== 'N/A') 
            ? String(json.studyNumber).trim() : null;
          // console.log(`ğŸ¤– Extracted Study Number (fallback): "${result.studyNumber}"`);
            
          if (json && json.hasHeader && json.headerPattern) {
            result.headerInfo = {
              hasHeader: json.hasHeader,
              headerPattern: json.headerPattern
            };
            // console.log(`ğŸ¤– âœ… HEADER DETECTED (fallback)!`);
            // console.log(`ğŸ¤– Header Pattern (fallback): "${json.headerPattern}"`);
            // console.log(`ğŸ¤– Has Header (fallback): ${json.hasHeader}`);
          } else {
            // console.log(`ğŸ¤– âŒ NO HEADER DETECTED (fallback)`);
            // console.log(`ğŸ¤– Reason (fallback): hasHeader=${json ? json.hasHeader : 'unknown'}, pattern=${json ? json.headerPattern : 'unknown'}`);
            result.headerInfo = null;
          }
        } catch (fallbackError) {
          // console.log(`ğŸ¤– âŒ Fallback JSON parsing also failed: ${fallbackError.message}`);
          result.headerInfo = null;
        }
      } else {
        // console.log(`ğŸ¤– âŒ No valid JSON found in response`);
        result.headerInfo = null;
      }
    }

    // å…œåº•ï¼šæ­£åˆ™åŸºäºå¸¸è§è¡Œ
    if (!result.studyNumber) {
      const lines = head.split(/\n|\r/);
      const candidates = [];
      for (const line of lines) {
        const t = line.trim();
        if (!t) continue;
        if (/study\s*(number|no\.)/i.test(t) || /protocol\s*(number|no\.)/i.test(t) || /protocol:\s*/i.test(t)) {
          const m = t.match(/([A-Z]{2,}[A-Z0-9\-]{2,})/i);
          if (m && m[1]) candidates.push(m[1]);
        }
      }
      if (candidates.length > 0) result.studyNumber = candidates[0];
    }

    // console.log('ğŸ¤– ===== FINAL AI EXTRACTION RESULT =====');
    // console.log(`ğŸ¤– Study Number: "${result.studyNumber || 'null'}"`);
    // if (result.headerInfo) {
    //   console.log(`ğŸ¤– Header Detected: âœ… YES`);
    //   console.log(`ğŸ¤– Header Pattern: "${result.headerInfo.headerPattern}"`);
    //   console.log(`ğŸ¤– Has Header: ${result.headerInfo.hasHeader}`);
    // } else {
    //   console.log(`ğŸ¤– Header Detected: âŒ NO`);
    // }
    // console.log('ğŸ¤– ===== AI HEADER DETECTION END =====');
    return result;
  } catch (err) {
    console.error('ğŸ¤– âŒ AI Study Number extraction FAILED:', err.message);
    console.error('ğŸ¤– Error details:', err);
    console.warn('ğŸ¤– Using regex fallback for Study Number extraction');
    // console.log('ğŸ¤– ===== AI HEADER DETECTION END (ERROR) =====');
    return { studyNumber: null, headerInfo: null };
  }
}

module.exports = {
  identifyAssessmentScheduleWithAI,
  extractStudyNumber,
  identifyAssessmentScheduleForPdfTables,
  /**
   * Identify repeating header/footer/page-number patterns and form name patterns
   * from first N pages' rows (line-level text) of a CRF PDF.
   * @param {Array<{page_number:number, rows:Array<{row_index:number, full_text:string}>}>} firstPagesRows
   * @returns {Promise<{success:boolean, header_patterns:string[], footer_patterns:string[], page_number_patterns:string[], form_name_patterns:string[]}>}
   */
  identifyCrfHeaderFooterAndFormPatterns: async function identifyCrfHeaderFooterAndFormPatterns(firstPagesRows) {
    try {
      if (!Array.isArray(firstPagesRows) || firstPagesRows.length === 0) {
        return { success: false, header_patterns: [], footer_patterns: [], page_number_patterns: [], form_name_patterns: [] };
      }

      // Build compact input: per page list of lines
      const pagesText = firstPagesRows.map(p => ({ page: p.page_number, lines: (p.rows || []).map(r => String(r.full_text || '').trim()).filter(Boolean) }));

      const instruction = `You are analyzing CRF (Case Report Form) pages to identify repeating patterns that appear consistently across multiple pages.

BACKGROUND: CRF documents typically have:
- Headers with version info, project names, generation timestamps
- Form titles like "Form: PARTICIPANT ENROLLMENT" 
- Footers with version codes, page numbers
- Consistent formatting across all pages

TASK: Find lines that repeat on MULTIPLE pages (3+ pages) with same structure but variable content.

EXAMPLES of typical CRF patterns:
- Header: "Version 8.100 CLINICAL QA 12MAR2023 | Protocol: XYZ-789-C01"
- Timestamp: "Document Generated: 22 Apr 2023 09:14:26 EST"
- Form title: "CRF: ADVERSE EVENTS" 
- Footer: "Version 8.100 CLINICAL QA 12MAR2023 [Document ID: 445]"
- Page number: "12 of 187" or "12/187"

IDENTIFY:
1) HEADER patterns (TOP 1-n repeatinglines of pages):
   - Version/software lines (e.g., "Version \\\\d+\\\\.\\\\d+ .+ \\\\| Protocol: .+" or "V\\\\d+\\\\.\\\\d+ PROD .+ Study Name: .+")
   - Generation timestamps (e.g., "Document Generated: .+ EST" or "Created On: .+ \\\\(UTC\\\\)" or "Generated On: .+ \\\\(GMT\\\\)")
   - Project identification lines
   - Form title lines that appear in header area (should be filtered from content)

2) FOOTER patterns (BOTTOM 1-n repeating lines of pages):
   - Version references with brackets/parentheses (e.g., "Version \\\\d+\\\\.\\\\d+ .+ \\\\[Document ID: \\\\d+\\\\]" or "V\\\\d+\\\\.\\\\d+ .+ \\\\(\\\\d+\\\\)")
   - Document identifiers

3) PAGE NUMBER patterns:
   - Format like "\\\\d+ of \\\\d+" or "\\\\d+/\\\\d+" or "Page \\\\d+"

4) FORM NAME patterns:
   - Lines starting with "Form:" or "CRF:" or other possible patterns (e.g., "Form:\\\\s*(.+)" or "CRF:\\\\s*(.+)")
   - Capture the actual form name in group 1

REQUIREMENTS:
- Return STRICT JSON: {"header_patterns":[], "footer_patterns":[], "page_number_patterns":[], "form_name_patterns":[]}
- Each pattern must be valid JavaScript regex string
- Use \\\\d+ for numbers, .+ for variable text, \\\\s+ for spaces
- Test patterns should match the STRUCTURE, allowing content to vary
- Only include patterns that appear on 3+ pages

ANALYZE THESE PAGES:\n${JSON.stringify(pagesText).slice(0, 12000)}`;

      const resp = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: instruction }],
        temperature: 0.1,
        max_tokens: 800
      });

      const raw = (resp.choices?.[0]?.message?.content || '').trim();
      let parsed = null;
      try { parsed = JSON.parse(raw); } catch (_) {
        const s = raw.indexOf('{'); const e = raw.lastIndexOf('}');
        if (s >= 0 && e > s) { try { parsed = JSON.parse(raw.slice(s, e + 1)); } catch (_) {} }
      }
      if (!parsed) return { success: false, header_patterns: [], footer_patterns: [], page_number_patterns: [], form_name_patterns: [] };

      // Validate and clean patterns
      const validatePattern = (pattern) => {
        try {
          new RegExp(pattern); // Test if valid regex
          return pattern.length > 2 && pattern.length < 500; // Reasonable length
        } catch (e) {
          console.warn(`âŒ Invalid regex pattern: ${pattern}`, e.message);
          return false;
        }
      };
      
      const normArr = (x) => Array.isArray(x) ? 
        x.map(s => String(s || '').trim())
         .filter(Boolean)
         .filter(validatePattern) : [];

      const result = {
        success: true,
        header_patterns: normArr(parsed.header_patterns),
        footer_patterns: normArr(parsed.footer_patterns),
        page_number_patterns: normArr(parsed.page_number_patterns),
        form_name_patterns: normArr(parsed.form_name_patterns)
      };

      // Log validation results
      console.log(`âœ… Pattern validation results:`);
      console.log(`ğŸ“‹ Header patterns: ${result.header_patterns.length}`);
      console.log(`ğŸ“‹ Footer patterns: ${result.footer_patterns.length}`);
      console.log(`ğŸ“‹ Page number patterns: ${result.page_number_patterns.length}`);
      console.log(`ğŸ“‹ Form name patterns: ${result.form_name_patterns.length}`);
      
      return result;
    } catch (e) {
      console.warn('identifyCrfHeaderFooterAndFormPatterns failed:', e.message);
      return { success: false, header_patterns: [], footer_patterns: [], page_number_patterns: [], form_name_patterns: [] };
    }
  },
  /**
   * Identify endpoint sections by titles only. Returns array of { index, category, cleaned_title }
   */
  identifyEndpoints: async function identifyEndpoints(sectionTitles) {
    try {
      if (!Array.isArray(sectionTitles) || sectionTitles.length === 0) return [];
      const numbered = sectionTitles.map((t, i) => `${i}: ${t || ''}`).join('\n');
      const prompt = `You are a clinical protocol analyst. Given an ordered list of section titles from a protocol, identify which entries correspond to study endpoints/objectives and classify each as Primary, Secondary, Safety, Exploratory or Other. Only return JSON array like: [{"index":12,"category":"Primary","cleaned_title":"Primary Endpoint"}].\n\nSECTION TITLES:\n${numbered}`;
      const resp = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.1,
        max_tokens: 300
      });
      const raw = (resp.choices?.[0]?.message?.content || '').trim();
      let json;
      try { json = JSON.parse(raw); } catch (_) {
        const s = raw.indexOf('{'); const e = raw.lastIndexOf('}');
        if (s >= 0 && e > s) json = JSON.parse(raw.slice(s, e + 1)); else json = [];
      }
      // Normalize category
      const norm = (c) => {
        const x = String(c || '').toLowerCase();
        if (x.includes('primary')) return 'Primary';
        if (x.includes('secondary')) return 'Secondary';
        if (x.includes('safety')) return 'Safety';
        if (x.includes('explor')) return 'Exploratory';
        return 'Other';
      };
      return (Array.isArray(json) ? json : []).map(it => ({
        index: Number(it.index),
        category: norm(it.category),
        cleaned_title: String(it.cleaned_title || sectionTitles[it.index] || '').replace(/^\s*\d+(?:\.\d+)*\s*[\)\-\:]?\s*/,'').trim()
      })).filter(it => Number.isInteger(it.index) && it.index >= 0 && it.index < sectionTitles.length);
    } catch (e) {
      console.warn('identifyEndpoints AI failed, falling back to rules:', e.message);
      // Rule-based fallback
      const results = [];
      (sectionTitles || []).forEach((title, idx) => {
        const t = String(title || '');
        const low = t.toLowerCase();
        const isEndpoint = /(endpoint|objective|efficacy)/i.test(t);
        if (!isEndpoint) return;
        let category = 'Other';
        if (low.includes('primary')) category = 'Primary';
        else if (low.includes('secondary')) category = 'Secondary';
        else if (low.includes('safety')) category = 'Safety';
        else if (low.includes('explor')) category = 'Exploratory';
        results.push({ index: idx, category, cleaned_title: t.replace(/^\s*\d+(?:\.\d+)*\s*[\)\-\:]?\s*/,'').trim() });
      });
      return results;
    }
  }
}; 